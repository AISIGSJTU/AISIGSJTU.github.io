---
layout: post
title: 论文SMORE:Enhancing GPU Utilization in Deep Learning Clusters by Serverless-based Co-location Scheduling被Transactions on Parallel and Distributed Systems(CCF A)期刊接收，恭喜俊涵！
date: 2025-03-01 14:00:00+0800
inline: false
related_posts: false
---
## 论文主题内容介绍

### 研究背景

随着深度学习（DL）技术的迅猛发展，其在自然语言处理、语音识别、推荐系统等领域的应用日益广泛，对计算资源的需求也日益增长。为此，大型研究机构和企业纷纷部署深度学习GPU集群，以提升计算速度和效率。然而，现有的多租户DL集群存在GPU低利用率的问题，严重阻碍了系统性能和模型吞吐量的提升。这一问题主要源于GPU资源的分配方法及分布式DL任务的资源利用特性。目前，尽管已有研究从任务导向和集群导向的角度出发，提出了多种优化GPU利用率的方案，但这些方法仍存在局限性，如将GPU视为不可分割的单元或仅支持特定类型的工作负载。

### 解决方案

论文提出了SMore框架，旨在通过选择性地将合适的无服务器函数工作负载和已经在运行的有服务器应用负载共置执行来提高GPU资源利用率。SMore框架主要由两个关键组件构成：

- **Performance Degradation Predictor (性能退化预测器)**：该组件包括一个双路预测器和一个多路预测器，用于预测不同工作负载共置执行性能退化程度
- **Degradation-aware Scheduler (性能退化感知调度器)**：该组件通过性能退化感知的函数调度来管理由于共置导致的工作负载性能下降，达到提高集群资源利用率的同时控制性能退化程度在一定范围内的目的。
- **Prewarmer (预热器)**：该组件一种基于长短期LSTM的预热策略，以解决无服务器深度学习推理函数的冷启动问题。

### 设计概述

SMore框架的核心架构包含预测器、调度器、预热器三个主要组件。SMore包括两个阶段：离线分析阶段和在线服务阶段。在离线阶段，系统收集独占执行下的工作负载性能数据，随机选择共置执行组合以训练初始模型，并预测剩余组合性能退化程度，生成完整性能退化表以供快速查询；同时，利用实际跟踪数据训练预热模块中的初始LS-LSTM。在线服务阶段，用户请求经调度器判断后分配GPU，预热模块收集请求并更新长短期LSTM，预测并提前加载模型；调度器监控资源使用和任务状态，定期更新集群状态，查询预测模块获取性能退化结果，进行调度并分配GPU资源；函数执行后，监控器跟踪实际性能退化，更新数据集以重新训练预测器，确保无服务器函数的高效执行和资源优化分配。

<div class="row">
    <div class="col-sm mt-3 mt-md-0">
        {% include figure.html loading="eager" path="assets/img/2025_03_01_figure1.png" class="img-fluid rounded z-depth-1" %}
    </div>
</div>
<div class="caption">
Fig 1. System Architecture.
</div>

Degradation-aware Scheduler采用的资源分配算法为提交的无服务器函数分配最合适的GPU资源。该算法优先处理队列中最高优先级的函数，其从GPU资源池中随机选择d个可能的GPU。这些GPU上未分配给深度学习训练任务的内存和计算核心被保留用于无服务器函数，称为空余的GPU资源。若某GPU的空余资源能满足函数需求，算法将使用预测器评估共置该函数带来的性能影响，并判断其是否在可接受范围内。当处理完所有选定GPU后，若没有GPU满足函数需求，则函数返回队列等待下一轮调度；若多个GPU满足需求，则选择性能影响最小的GPU进行函数部署。

<div class="row">
    <div class="col-sm mt-3 mt-md-0">
        {% include figure.html loading="eager" path="assets/img/2025_03_01_figure2.png" class="img-fluid rounded z-depth-1" %}
    </div>
</div>
<div class="caption">
Fig2. Detailed Algorithms.
</div>


## 实验结果

原型测试结果显示，SMore在GPU利用率方面相较于独占执行条件实现了最高34%的提升，同时并未出现显著的性能退化。这一成果证实了SMore在优化GPU资源分配、提高利用率方面的有效性和稳定性，为无服务器计算环境中的资源管理提供了有力的解决方案。

## 刘俊涵个人介绍

- 本科毕业院校：上海交通大学
- 研究方向：Severless范式，资源调度
- 荣誉奖励：
  - 2020年上海交通大学松下育英奖学金
  - 2021年上海交通大学华为奖学金
  - 2023年上海交通大学“校优秀毕业生”
